{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Import required Libraries\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import cv2\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras import Model, callbacks\n",
        "from tensorflow.keras.layers import Dense, Flatten, Reshape, UpSampling2D,BatchNormalization, Dropout, Conv2D, Conv2DTranspose\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Rescaling\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "import os\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:34.62413Z",
          "iopub.execute_input": "2023-01-03T13:46:34.624652Z",
          "iopub.status.idle": "2023-01-03T13:46:34.632358Z",
          "shell.execute_reply.started": "2023-01-03T13:46:34.624612Z",
          "shell.execute_reply": "2023-01-03T13:46:34.631398Z"
        },
        "trusted": true,
        "id": "cXiXm5gCAe-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load data\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:34.634476Z",
          "iopub.execute_input": "2023-01-03T13:46:34.635561Z",
          "iopub.status.idle": "2023-01-03T13:46:34.913916Z",
          "shell.execute_reply.started": "2023-01-03T13:46:34.63552Z",
          "shell.execute_reply": "2023-01-03T13:46:34.91283Z"
        },
        "trusted": true,
        "id": "QxhszPi3Ae-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# considering that the generator generates good images in cases where we use a set of images that are similar to each other:\n",
        "x_train = x_train[y_train == 7]\n",
        "y_train = y_train[y_train == 7]"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:34.915622Z",
          "iopub.execute_input": "2023-01-03T13:46:34.916031Z",
          "iopub.status.idle": "2023-01-03T13:46:34.934487Z",
          "shell.execute_reply.started": "2023-01-03T13:46:34.915993Z",
          "shell.execute_reply": "2023-01-03T13:46:34.932113Z"
        },
        "trusted": true,
        "id": "HA22ARbXAe-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter BUFFER_SIZE so that the sample size is a multiple of BATCH_SIZE\n",
        "BUFFER_SIZE = x_train.shape[0]\n",
        "BATCH_SIZE = 100\n",
        "\n",
        "BUFFER_SIZE = BUFFER_SIZE // BATCH_SIZE * BATCH_SIZE\n",
        "x_train = x_train[:BUFFER_SIZE]\n",
        "y_train = y_train[:BUFFER_SIZE]\n",
        "print(f'Input data shape: {x_train.shape}')\n",
        "print(f'Number of labels: {y_train.size}')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:34.938007Z",
          "iopub.execute_input": "2023-01-03T13:46:34.938885Z",
          "iopub.status.idle": "2023-01-03T13:46:34.954742Z",
          "shell.execute_reply.started": "2023-01-03T13:46:34.938819Z",
          "shell.execute_reply": "2023-01-03T13:46:34.953723Z"
        },
        "trusted": true,
        "id": "xntSVXvLAe-4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data normalization\n",
        "x_train = x_train / 255\n",
        "x_test = x_test / 255\n",
        "\n",
        "# We form tensors for training and test samples\n",
        "x_train = np.reshape(x_train, (len(x_train), 28, 28, 1))\n",
        "x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\n",
        "\n",
        "# Splitting the training sample into BATCHES\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:34.96999Z",
          "iopub.execute_input": "2023-01-03T13:46:34.970357Z",
          "iopub.status.idle": "2023-01-03T13:46:35.196075Z",
          "shell.execute_reply.started": "2023-01-03T13:46:34.970321Z",
          "shell.execute_reply": "2023-01-03T13:46:35.194905Z"
        },
        "trusted": true,
        "id": "8q_qcrdJAe-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cnt_imgs = 32\n",
        "counter = 0\n",
        "IMAGE_SIZE = (64, 64)\n",
        "plt.figure(figsize=(28, 10))\n",
        "for img in x_train:\n",
        "    plt.subplot(4, 8, counter + 1)\n",
        "    draw_img = cv2.resize(img, IMAGE_SIZE)\n",
        "    plt.imshow(draw_img, cmap='gray')\n",
        "    plt.axis('off')\n",
        "    counter += 1\n",
        "    if counter == cnt_imgs:\n",
        "        break"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:35.19742Z",
          "iopub.execute_input": "2023-01-03T13:46:35.200333Z",
          "iopub.status.idle": "2023-01-03T13:46:37.075277Z",
          "shell.execute_reply.started": "2023-01-03T13:46:35.200291Z",
          "shell.execute_reply": "2023-01-03T13:46:37.074371Z"
        },
        "trusted": true,
        "id": "21vj3E66Ae-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# loss function\n",
        "cross_entropy = BinaryCrossentropy(from_logits=True)\n",
        "\n",
        "def generator_loss(fake_output):\n",
        "    \"\"\"Function of finding the value of the loss function for the generator (for BATCH)\"\"\"\n",
        "    loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "    return loss\n",
        "\n",
        "\n",
        "def discriminator_loss(real_output, fake_output):\n",
        "    \"\"\"Function of finding the value of the loss function for the discriminator (for BATCH)\"\"\"\n",
        "    real_loss = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.076741Z",
          "iopub.execute_input": "2023-01-03T13:46:37.077467Z",
          "iopub.status.idle": "2023-01-03T13:46:37.085024Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.077428Z",
          "shell.execute_reply": "2023-01-03T13:46:37.083745Z"
        },
        "trusted": true,
        "id": "8LaRqDy8Ae-6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator_optimizer = tf.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.optimizers.Adam(1e-4)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.08726Z",
          "iopub.execute_input": "2023-01-03T13:46:37.087776Z",
          "iopub.status.idle": "2023-01-03T13:46:37.098564Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.087741Z",
          "shell.execute_reply": "2023-01-03T13:46:37.097721Z"
        },
        "trusted": true,
        "id": "6e0riDdcAe-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We will feed a vector of independent random variables of the hidden dim dimension to the input of the generator\n",
        "hidden_dim = 2"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.100086Z",
          "iopub.execute_input": "2023-01-03T13:46:37.100444Z",
          "iopub.status.idle": "2023-01-03T13:46:37.112288Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.10041Z",
          "shell.execute_reply": "2023-01-03T13:46:37.111286Z"
        },
        "trusted": true,
        "id": "pV082nkuAe-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# First, let's create a generator model\n",
        "generator = Sequential(name='generator')\n",
        "generator.add(Dense(7 * 7 * 256, activation='relu', input_shape=(hidden_dim, )))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Reshape((7, 7, 256)))  # got a tensor\n",
        "generator.add(Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', activation='relu'))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', activation='relu'))\n",
        "generator.add(BatchNormalization())\n",
        "generator.add(Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', activation='sigmoid'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.115864Z",
          "iopub.execute_input": "2023-01-03T13:46:37.116154Z",
          "iopub.status.idle": "2023-01-03T13:46:37.210055Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.116128Z",
          "shell.execute_reply": "2023-01-03T13:46:37.20912Z"
        },
        "trusted": true,
        "id": "zJurhk_UAe-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.212748Z",
          "iopub.execute_input": "2023-01-03T13:46:37.213164Z",
          "iopub.status.idle": "2023-01-03T13:46:37.220128Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.213125Z",
          "shell.execute_reply": "2023-01-03T13:46:37.219147Z"
        },
        "trusted": true,
        "id": "LEMunI3bAe-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# next let's create a discriminator model\n",
        "discriminator = Sequential(name='discriminator')\n",
        "discriminator.add(Conv2D(64, (5, 5), strides=(2, 2), padding='same', activation='elu', input_shape=(28, 28, 1)))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Conv2D(128, (5, 5), strides=(2, 2), padding='same', activation='elu'))\n",
        "discriminator.add(Dropout(0.3))\n",
        "discriminator.add(Flatten())\n",
        "discriminator.add(Dense(64, activation='relu'))\n",
        "discriminator.add(Dense(1, activation='sigmoid'))"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.221941Z",
          "iopub.execute_input": "2023-01-03T13:46:37.222723Z",
          "iopub.status.idle": "2023-01-03T13:46:37.273822Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.222664Z",
          "shell.execute_reply": "2023-01-03T13:46:37.272883Z"
        },
        "trusted": true,
        "id": "SACeV9g0Ae-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "discriminator.summary()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.275353Z",
          "iopub.execute_input": "2023-01-03T13:46:37.275733Z",
          "iopub.status.idle": "2023-01-03T13:46:37.282383Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.275696Z",
          "shell.execute_reply": "2023-01-03T13:46:37.281145Z"
        },
        "trusted": true,
        "id": "Zyi5y-shAe-8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compiling neural networks\n",
        "generator.compile(optimizer=generator_optimizer, loss='binary_crossentropy')\n",
        "discriminator.compile(optimizer=discriminator_optimizer, loss='binary_crossentropy')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.28742Z",
          "iopub.execute_input": "2023-01-03T13:46:37.287921Z",
          "iopub.status.idle": "2023-01-03T13:46:37.302728Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.287883Z",
          "shell.execute_reply": "2023-01-03T13:46:37.301688Z"
        },
        "trusted": true,
        "id": "YU23BRd7Ae-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generator and Discriminator training\n",
        "@tf.function\n",
        "def train_step(images) -> (float, float):\n",
        "    \"\"\"Function for updating weight coefficients at one training step (for one BATCH)\"\"\"\n",
        "    noise = tf.random.normal([BATCH_SIZE, hidden_dim])\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        generated_images = generator(noise, training=True)\n",
        "\n",
        "        real_output = discriminator(images, training=True)\n",
        "        fake_output = discriminator(generated_images, training=True)\n",
        "\n",
        "        gen_loss = generator_loss(fake_output)\n",
        "        disc_loss = discriminator_loss(real_output, fake_output)\n",
        "\n",
        "        generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "        discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "        generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))\n",
        "        discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))\n",
        "        return gen_loss, disc_loss\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.306563Z",
          "iopub.execute_input": "2023-01-03T13:46:37.307102Z",
          "iopub.status.idle": "2023-01-03T13:46:37.345136Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.307073Z",
          "shell.execute_reply": "2023-01-03T13:46:37.344116Z"
        },
        "trusted": true,
        "id": "99phIgIwAe-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# the learning process for all epochs\n",
        "def train(dataset,  epochs) -> None:\n",
        "    \"\"\"A function to start the learning process for all epochs for the generator and discriminator\n",
        "    dataset: a set of real images that we store in  generator\"\"\"\n",
        "    history = []\n",
        "    max_print_label = 10\n",
        "    th = BUFFER_SIZE // (BATCH_SIZE * max_print_label)\n",
        "\n",
        "    for epoch in range(1, EPOCHS + 1):\n",
        "        print(f'{epoch}/{EPOCHS}: ', end='')\n",
        "        start = time.time()\n",
        "        n = 0\n",
        "        gen_loss_epoch = 0\n",
        "        for image_batch in dataset:\n",
        "            gen_loss, disc_loss = train_step(image_batch)\n",
        "            gen_loss_epoch += K.mean(gen_loss)\n",
        "            if (n % th == 0):\n",
        "                print('=', end='')\n",
        "            n += 1\n",
        "        print('>', end = ' ')\n",
        "\n",
        "        history += [gen_loss_epoch / n]\n",
        "        print(': loss = ' + str(history[-1]))\n",
        "        print(f'The time of the epoch {epoch} is: {time.time() - start} second')\n",
        "    return history"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.348743Z",
          "iopub.execute_input": "2023-01-03T13:46:37.349045Z",
          "iopub.status.idle": "2023-01-03T13:46:37.359599Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.349017Z",
          "shell.execute_reply": "2023-01-03T13:46:37.358386Z"
        },
        "trusted": true,
        "id": "ubuz22IQAe-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # Starting the learning process\n",
        "EPOCHS = 100\n",
        "gen_history = train(train_dataset, EPOCHS)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:46:37.36118Z",
          "iopub.execute_input": "2023-01-03T13:46:37.361591Z",
          "iopub.status.idle": "2023-01-03T13:48:44.164496Z",
          "shell.execute_reply.started": "2023-01-03T13:46:37.361554Z",
          "shell.execute_reply": "2023-01-03T13:48:44.163373Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "trusted": true,
        "id": "DObamvNLAe-9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(24, 10))\n",
        "plt.title('Visualization of the generator learning process', fontsize=16)\n",
        "plt.plot(np.arange(1, EPOCHS + 1), gen_history)\n",
        "plt.xlabel('Epochs', fontsize=16)\n",
        "plt.ylabel('Loss', fontsize=16)\n",
        "plt.xticks(fontsize=16)\n",
        "plt.yticks(fontsize=16)\n",
        "plt.xlim(1, EPOCHS)\n",
        "plt.grid()\n",
        "plt.legend(fontsize=16)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:48:44.166239Z",
          "iopub.execute_input": "2023-01-03T13:48:44.166611Z",
          "iopub.status.idle": "2023-01-03T13:48:44.442602Z",
          "shell.execute_reply.started": "2023-01-03T13:48:44.166575Z",
          "shell.execute_reply": "2023-01-03T13:48:44.441628Z"
        },
        "trusted": true,
        "id": "Kn0DSvSiAe--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n = 4\n",
        "total = 2 * n + 1\n",
        "cnter = 0\n",
        "plt.figure(figsize=(28, 8))\n",
        "\n",
        "num = 1\n",
        "for i in range(-n, n + 1):\n",
        "    for j in range(-n, n + 1):\n",
        "        ax = plt.subplot(7, 11, num)\n",
        "        num += 1\n",
        "        img = generator.predict(np.expand_dims([0.5 * i / n, 0.5 * j / n], axis=0))\n",
        "        plt.imshow(img[0, :, :, 0], cmap='gray')\n",
        "        plt.axis('off')\n",
        "        if num == 78:\n",
        "            break\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-01-03T13:48:44.444396Z",
          "iopub.execute_input": "2023-01-03T13:48:44.445075Z",
          "iopub.status.idle": "2023-01-03T13:48:50.710106Z",
          "shell.execute_reply.started": "2023-01-03T13:48:44.445035Z",
          "shell.execute_reply": "2023-01-03T13:48:50.708974Z"
        },
        "trusted": true,
        "id": "GehHpIKDAe--"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}